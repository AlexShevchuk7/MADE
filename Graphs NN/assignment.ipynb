{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6383670d95f34a5d8e5a7b8bab521e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbd28f6a17924d24b17a44f9f422d62e",
              "IPY_MODEL_e2f121fc79e14c0597c2d950b658282e",
              "IPY_MODEL_5fd1d9dd7bf74aa09cacb109b1516aea"
            ],
            "layout": "IPY_MODEL_8517834449e9476f93e6ddf4a52ed3eb"
          }
        },
        "8517834449e9476f93e6ddf4a52ed3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd28f6a17924d24b17a44f9f422d62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03213a37b3f6490cb411b9bd4b3f6777",
            "placeholder": "​",
            "style": "IPY_MODEL_bbe27cf1be464fa8b5bce83d08c77bdd",
            "value": "100%"
          }
        },
        "e2f121fc79e14c0597c2d950b658282e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcc4f031dc544ef902fb5fb521cd9c3",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0787bd454fa443edbca3267a0c44c54c",
            "value": 500
          }
        },
        "5fd1d9dd7bf74aa09cacb109b1516aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a694afaddb51498ba74b1dc4d5f48698",
            "placeholder": "​",
            "style": "IPY_MODEL_83d389ec3e6f4b45b106b926818b565a",
            "value": " 500/500 [01:14&lt;00:00,  3.92it/s]"
          }
        },
        "bbe27cf1be464fa8b5bce83d08c77bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03213a37b3f6490cb411b9bd4b3f6777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0787bd454fa443edbca3267a0c44c54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bcc4f031dc544ef902fb5fb521cd9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d389ec3e6f4b45b106b926818b565a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a694afaddb51498ba74b1dc4d5f48698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb4sGdJhMDjy"
      },
      "source": [
        "# Assignment — Deep Recurrent Graph Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM1VMGp9JW8X"
      },
      "source": [
        "### Task 1. Recurrent attention GNN (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M4hI19NmaSQr",
        "outputId": "ee6beccd-6716-4f5a-8b57-840fe7b2e0c4"
      },
      "source": [
        "#!pip install dgl -f https://data.dgl.ai/wheels/repo.html -q\n",
        "!pip install dgl-cu113 -f https://data.dgl.ai/wheels/repo.html -q\n",
        "import dgl\n",
        "dgl.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.7.2'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhMp8pbWbl_7"
      },
      "source": [
        "import dgl\n",
        "import dgl.nn as dnn\n",
        "import dgl.function as fn\n",
        "from dgl.data import DGLDataset, GINDataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributions as D\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import requests"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58lh0VWv66zO",
        "outputId": "0434ae3e-0c38-41bd-e8d4-4bc01620130d"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipT9aDuuPLcA"
      },
      "source": [
        "The traditional graph generation approaches (Erdos-Renyi, Barabasi-Albert, etc.) can be used to efficiently generate synthetic graphs that have certain properties. Such models can give us insight into how certain graph structures might arise in the real world. However, they rely on a fixed, handcrafted generation process. On the other side, deep generation approaches will seek to learn a generative model on a set of training graphs. This assignment is dedicated to a such generative model inspired by GRAN [Liao et al., 2019](https://arxiv.org/pdf/1910.00760.pdf). \n",
        "\n",
        "The idea of the model is to generate a graph by adding nodes one-by-one. Features of existing nodes are fed into a recurrent attention GNN for creating node embedding. Then the embeddings used for estimating parameters of Bernoulli distributions that can model probabilities of new edges. First, let us create a recurrent attention model for node embedding. Each layer in the network takes a graph with node states $h^l$ and propagate them as follows:\n",
        "\n",
        "$$h^{l+1}_i = \\text{GRU}\\left(h^l_i, \\sum_{j\\in\\mathcal{N}(i)} a_{ij}^l m_{ij}^l\\right)$$\n",
        "$$m_{ij}^l = f(h_i^l - h_j^l)$$\n",
        "$$a_{ij}^l = g(h_i^l - h_j^l)$$\n",
        "\n",
        "where $\\mathcal{N}(i)$ is a neighborhood of the node $i$, $f(\\cdot)$ is the message function, $g(\\cdot)$ is the attention head (both are two-layer MLP). The initial node states are node features. The node embeddings are final node states.\n",
        "\n",
        "Write a function `_prop` that takes a graph, node states, index of a layer and propagate current node states, returns next node states.\n",
        "\n",
        "*Hints:* \n",
        "* *apply the DGL message passing framework*\n",
        "* *`fn.u_sub_v` for creating messages — difference between adjacent node states*\n",
        "* *`graph.apply_edges` for storing the messages into edge features*\n",
        "* *`graph.update_all` for reduction messages from adjacent edges (summation in this task)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "5n3W7eniNOeY",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1c9ff854c5afabfce87304a51672bb7a",
          "grade": false,
          "grade_id": "cell-bc0c1855de705635",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "class RecurrentGNN(nn.Module):\n",
        "    def __init__(self, node_state_dim, hid_dim, num_layer):\n",
        "        super().__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.update_func = nn.ModuleList([\n",
        "            nn.GRUCell(input_size=hid_dim, hidden_size=node_state_dim) \n",
        "            for _ in range(self.num_layer)\n",
        "        ])\n",
        "        self.msg_func = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                *[\n",
        "                    nn.Linear(node_state_dim, hid_dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hid_dim, hid_dim)\n",
        "                ]) for _ in range(self.num_layer)\n",
        "        ])\n",
        "        self.att_head = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                *[\n",
        "                    nn.Linear(node_state_dim, hid_dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hid_dim, hid_dim),\n",
        "                    nn.Sigmoid()\n",
        "                ]) for _ in range(self.num_layer)\n",
        "        ])\n",
        "\n",
        "    def _prop(self, graph, state, layer_idx=0):\n",
        "        graph.ndata['state'] = state\n",
        "        graph.apply_edges(fn.u_sub_v('state', 'state', 'sub'))\n",
        "\n",
        "        graph.edata['f'] = self.msg_func[layer_idx](graph.edata['sub'])\n",
        "        graph.edata['g'] = self.att_head[layer_idx](graph.edata['sub'])\n",
        "\n",
        "        graph.edata['mult'] = graph.edata['f'] * graph.edata['g']    \n",
        "        \n",
        "        graph.update_all(fn.copy_e('mult', 'msg'), fn.sum('msg', 'res'))\n",
        "            \n",
        "        output = self.update_func[layer_idx](graph.ndata['res'], graph.ndata['state'])\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, graph, feat):\n",
        "        state = feat\n",
        "        for i in range(self.num_layer):\n",
        "            if i > 0:\n",
        "                state = F.relu(state)\n",
        "            state = self._prop(graph, state, layer_idx=i)\n",
        "        return state"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIvzxROMxlv3",
        "outputId": "f44016b2-61b9-4a6c-a215-1220fb8b54ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(0)\n",
        "model = RecurrentGNN(node_state_dim=16, hid_dim=128, num_layer=5)\n",
        "graph = dgl.from_networkx(nx.grid_2d_graph(2, 2))\n",
        "feat = torch.ones(4, 16)\n",
        "\n",
        "model._prop(graph, feat, layer_idx=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6579, 0.4505, 0.7249, 0.5690, 0.5839, 0.2217, 0.7943, 0.6908, 0.7634,\n",
              "         0.1489, 0.5663, 0.6020, 0.6967, 0.7424, 0.1602, 0.4054],\n",
              "        [0.6579, 0.4505, 0.7249, 0.5690, 0.5839, 0.2217, 0.7943, 0.6908, 0.7634,\n",
              "         0.1489, 0.5663, 0.6020, 0.6967, 0.7424, 0.1602, 0.4054],\n",
              "        [0.6579, 0.4505, 0.7249, 0.5690, 0.5839, 0.2217, 0.7943, 0.6908, 0.7634,\n",
              "         0.1489, 0.5663, 0.6020, 0.6967, 0.7424, 0.1602, 0.4054],\n",
              "        [0.6579, 0.4505, 0.7249, 0.5690, 0.5839, 0.2217, 0.7943, 0.6908, 0.7634,\n",
              "         0.1489, 0.5663, 0.6020, 0.6967, 0.7424, 0.1602, 0.4054]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vTPalmcpN8Ho",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a05aac68e5635b1617c6f62c88471b5a",
          "grade": true,
          "grade_id": "cell-f96cbf56be9f29b4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true
      },
      "source": [
        "torch.manual_seed(0)\n",
        "model = RecurrentGNN(node_state_dim=16, hid_dim=128, num_layer=5)\n",
        "graph = dgl.from_networkx(nx.grid_2d_graph(2, 2))\n",
        "feat = torch.ones(4, 16)\n",
        "out = model._prop(graph, feat, layer_idx=0)\n",
        "assert out.shape == (4, 16)\n",
        "test_ans = out.detach().numpy()[0, :3].round(2)\n",
        "assert np.all(np.isclose(test_ans, [0.68, 0.57, 0.29]))\n",
        "out = model._prop(graph, feat, layer_idx=1)\n",
        "test_ans = out.detach().numpy()[0, :3].round(2)\n",
        "assert np.all(np.isclose(test_ans, [0.66, 0.45, 0.72]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH7DZP0yJlBh"
      },
      "source": [
        "### Task 2. Bernoulli probabilistic model (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wlNUil8cxW2"
      },
      "source": [
        "Next, the generation process is performed as follows: \n",
        "1. Start from a graph with a single node\n",
        "2. Produce parameters of the distributions based on graph\n",
        "3. Add new node to the graph and sample edges from new node using the distributions\n",
        "4. Repeat steps 2-3 to the desired number of nodes\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/netspractice/advanced_gnn/main/assignment_recurrent_generation/gnn_generation.png' width=600>\n",
        "\n",
        "For example, we have the graph with 4 nodes, we produce 4 parameters of 4 independent Bernoulli distributions, and then sample 4 boolean values. Let it be (0, 0, 1, 1), then we connect the new node to the third and fourth nodes. In this assignment, let us use MLP for converting node embeddings into 1-dimensional parameters of Bernoulli distributions.\n",
        "\n",
        "Write a class `BernoulliGNN`. The network takes a graph and node features, propagate them through a recurrent GNN, then through a two-layer MLP and returns parameters of distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "dyzbOQLNuic_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63efe4b93c5a1f36cdfca78469a8f7e8",
          "grade": false,
          "grade_id": "cell-78cbc86ac50e4417",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "class BernoulliGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, num_layer):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.gru = RecurrentGNN(node_state_dim=in_dim, hid_dim=hid_dim, num_layer=num_layer)\n",
        "        self.mlp = nn.Sequential(nn.Linear(in_dim, in_dim), \n",
        "                                 nn.Linear(in_dim, 1), \n",
        "                                 nn.Sigmoid()\n",
        "                                )\n",
        "        \n",
        "    def forward(self, graph, feat):\n",
        "        x = self.gru(graph, feat)\n",
        "        out = self.mlp(x)       \n",
        "        \n",
        "        return out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q50tDwvwxlv8",
        "outputId": "89b51e67-378b-48e6-e015-98260fb0ebac"
      },
      "source": [
        "model = BernoulliGNN(in_dim=16, hid_dim=128, num_layer=5)\n",
        "graph = dgl.from_networkx(nx.grid_2d_graph(2, 2))\n",
        "feat = torch.ones(4, 16)\n",
        "theta = model(graph, feat)\n",
        "theta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5090],\n",
              "        [0.5090],\n",
              "        [0.5090],\n",
              "        [0.5090]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "M4JsZZbewXnZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "35e2efd676afbf918915f0d9f2f3bdcd",
          "grade": true,
          "grade_id": "cell-19da05874c299841",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "model = BernoulliGNN(in_dim=16, hid_dim=128, num_layer=5)\n",
        "graph = dgl.from_networkx(nx.grid_2d_graph(2, 2))\n",
        "feat = torch.ones(4, 16)\n",
        "theta = model(graph, feat)\n",
        "assert theta.shape == (4, 1)\n",
        "assert torch.all((0 <= theta) & (theta <= 1))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HftgECj1_UF"
      },
      "source": [
        "Write a function `sample` that takes parameters `theta` and returns realization from corresponding Bernoulli distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "VdLe-OJX0pzU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "76cc2d227068bd15198656a3da565c5f",
          "grade": false,
          "grade_id": "cell-12156abdd3705a84",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def sample(theta):\n",
        "    return torch.bernoulli(theta)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e-clBnH11XBe",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b05c58abc23f201b03185cb7bd75b275",
          "grade": true,
          "grade_id": "cell-7edae2ecaed11649",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "theta = torch.tensor([[0.999], [0.001], [0.999], [0.999]])\n",
        "assert torch.all(sample(theta) == torch.tensor([[1], [0], [1], [1]]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_zD70dbJ6t8"
      },
      "source": [
        "### Task 3. Generation process (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUODvih43aqW"
      },
      "source": [
        "Let us check what we can generate using an untrained model. Let the node features be one-hot encoded vector with node index. The node features dimension can be larger than the number of nodes, so let it be padded with zeros on the right. For example, 6-dimensional node features in a graph with 4 nodes be:\n",
        "\n",
        "$$F = \\begin{pmatrix}\n",
        "1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
        "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
        "0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "\n",
        "Write a function `generate_graph` that takes a model, number of nodes, node features dimension and returns a generated graph and node features. The generated graph is undirected and contains self-loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "ygYD-5LF2kop",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ea91d6bd9dc4072d54676cb84dec7eaf",
          "grade": false,
          "grade_id": "cell-6b5878a6f49ce0c8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def generate_graph(model, n_nodes, feat_dim):\n",
        "    # starting from a graph with a single node\n",
        "    feat = torch.zeros(1, feat_dim).to(device)\n",
        "    feat[0, 0] = 1\n",
        "    graph = dgl.graph(data=([0], [0])).to(device)\n",
        "    for i in range(1, n_nodes):\n",
        "        nodes = graph.nodes()\n",
        "        src_nodes, dst_nodes = graph.edges()\n",
        "        theta = model(graph, feat)\n",
        "        new_edges = sample(theta).to(torch.bool).squeeze()\n",
        "        \n",
        "        new_src_nodes = nodes[new_edges]\n",
        "        \n",
        "        new_src_nodes = torch.cat((new_src_nodes.view(-1), torch.tensor([i])))\n",
        "        src_nodes = torch.cat((src_nodes, new_src_nodes)).squeeze()\n",
        "        \n",
        "        new_dst_nodes = torch.tensor([i] * new_src_nodes.shape[0])\n",
        "        dst_nodes = torch.cat((dst_nodes, new_dst_nodes))\n",
        "        \n",
        "        src_nodes = torch.cat((src_nodes, new_dst_nodes[:-1]))\n",
        "        dst_nodes = torch.cat((dst_nodes, new_src_nodes[:-1]))\n",
        "        \n",
        "        graph = dgl.graph(data=(src_nodes, dst_nodes)).to(device)\n",
        "        \n",
        "        pad_with = feat_dim - graph.number_of_nodes()\n",
        "        feat = F.pad(torch.diag(torch.ones(graph.number_of_nodes())), (0, pad_with), 'constant', 0)\n",
        "                \n",
        "    return graph, feat"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHHU_aLAxlwB"
      },
      "source": [
        "model = BernoulliGNN(in_dim=16, hid_dim=128, num_layer=5)\n",
        "model = model.to(device)\n",
        "graph, feat = generate_graph(model, n_nodes=16, feat_dim=16)\n",
        "graph, feat = graph.cpu(), feat.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "S7W9aQD86_QQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0d00e36282739d62b9a3f6c37a9e24dd",
          "grade": true,
          "grade_id": "cell-84b89929d40102cf",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "1efd2f33-cbdd-4490-bc03-295828269461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "source": [
        "model = BernoulliGNN(in_dim=16, hid_dim=128, num_layer=5)\n",
        "model = model.to('cpu')\n",
        "graph, feat = generate_graph(model, n_nodes=16, feat_dim=16)\n",
        "graph, feat = graph.cpu(), feat.cpu()\n",
        "\n",
        "assert graph.number_of_nodes() == 16\n",
        "assert graph.number_of_edges() > 1\n",
        "assert feat.shape == (16, 16)\n",
        "assert torch.all(feat[:3, :3] == torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n",
        "adj = graph.adj().to_dense()\n",
        "assert torch.all(adj[range(10), range(10)] == 1)\n",
        "assert torch.all(adj == adj.t())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DGLError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1233b3277f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulliGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-2ba39a62c8e0>\u001b[0m in \u001b[0;36mgenerate_graph\u001b[0;34m(model, n_nodes, feat_dim)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5397\u001b[0m         \u001b[0;31m# 1. Copy graph structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5398\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5400\u001b[0m         \u001b[0;31m# 2. Copy features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mcopy_to\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroCopyTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshared_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mdgl/_ffi/_cython/./base.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.CALL\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDGLError\u001b[0m: [19:21:01] /opt/dgl/src/runtime/c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1d55fed08f]\n  [bt] (1) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x374) [0x7f1d567beb04]\n  [bt] (2) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DLContext, bool)+0x1f4) [0x7f1d567b87e4]\n  [bt] (3) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyFromTo(DLTensor*, DLTensor*, void*)+0x23d) [0x7f1d567da66d]\n  [bt] (4) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xee) [0x7f1d56813cce]\n  [bt] (5) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::aten::COOMatrix::CopyTo(DLContext const&) const+0x7d) [0x7f1d56931dbd]\n  [bt] (6) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x292) [0x7f1d56922532]\n  [bt] (7) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7f1d56825415]\n  [bt] (8) /usr/local/lib/python3.7/dist-packages/dgl/libdgl.so(+0xa7e80b) [0x7f1d5683280b]\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs-UPHzeAkfv"
      },
      "source": [
        "G = nx.Graph(graph.to_networkx())\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "nx.draw_kamada_kawai(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfP-pzVIKBMm"
      },
      "source": [
        "### Task 4. Negative log likelihood loss (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXpTLlJYDYUv"
      },
      "source": [
        "We aim to train the model so that it can be able to generate realistic networks. Fortunately, explicit parametric models can be optimized by maximim likelihood estimation. In torch, it can be performed by minimization negative log likelihood loss.\n",
        "\n",
        "Write a function `bernoulli_nll` that takes parameters `theta` and a realization `label`, returns the mean negative log likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "kWgOFroxEuEr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6a19e6e63b9480f848857b4239a4454e",
          "grade": false,
          "grade_id": "cell-665616c5e24079d5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def bernoulli_nll(theta, label):\n",
        "    \n",
        "    return -(torch.log(theta) * label + torch.log(1 - theta) * (1 - label)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-aE50I3wFGAh",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4e58488c8b3c265d1fad8cb9c50e296c",
          "grade": true,
          "grade_id": "cell-13bcfd77216f0173",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "theta = torch.tensor([[0.999], [0.001], [0.999], [0.999]])\n",
        "label = torch.tensor([[1.], [0.], [1.], [1.]])\n",
        "loss1 = bernoulli_nll(theta, label)\n",
        "label = torch.tensor([[1.], [0.], [0.], [1.]])\n",
        "loss2 = bernoulli_nll(theta, label)\n",
        "label = torch.tensor([[0.], [1.], [0.], [0.]])\n",
        "loss3 = bernoulli_nll(theta, label)\n",
        "assert loss1 < loss2 < loss3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmhWD19UJKDc"
      },
      "source": [
        "### Task 5. Dataloader for grid subgraphs (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR5WEdfjR5fK"
      },
      "source": [
        "Let us train the model to generate 2d grid graphs, it can be useful for visual verification of the model. The auxiliary function `grid_graphs` generates grid graphs with one-hot encoded node features and returns a list of DGL graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPz4ToXKRQwC"
      },
      "source": [
        "def grid_graphs(min_dim, max_dim, n_graphs, feat_dim):\n",
        "    graphs = []\n",
        "    for i in range(n_graphs):\n",
        "        i = np.random.randint(min_dim, max_dim + 1)\n",
        "        j = np.random.randint(min_dim, max_dim + 1)\n",
        "        G = nx.grid_2d_graph(i, j)\n",
        "        graph = dgl.from_networkx(G)\n",
        "        graph = graph.add_self_loop()\n",
        "        feat = torch.eye(graph.number_of_nodes())\n",
        "        feat = F.pad(feat, [0, feat_dim - graph.number_of_nodes(), 0, 0])\n",
        "        graph.ndata['feat'] = feat\n",
        "        graphs.append(graph)\n",
        "    return graphs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0id9WuwaIGS"
      },
      "source": [
        "nx.draw(grid_graphs(4, 4, 1, 16)[0].to_networkx())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHnd6lHaSilc"
      },
      "source": [
        "Next, we need to define the train dataset where graphs are subgraphs from initial grid graphs and labels are next node indicator vectors. For a given graph, the label defines connections to the next node. For example, let the left depicted graph be a subgraph and the next node be 5, then a label be a column-vector `[[0], [0], [1], [1]]`.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/netspractice/advanced_gnn/main/assignment_recurrent_generation/gnn_generation.png' width=600>\n",
        "\n",
        "Write a function `process` that divides each graph into N subgraphs and prepares N labels where N is the number of nodes minus one. Then it stores all subgraphs and labels into `self.graphs` and `self.labels` lists.\n",
        "\n",
        "For example, the dataset on the single graph with 5 nodes looks like:\n",
        "* subgraph with nodes [0], label for the node 1\n",
        "* subgraph with nodes [0, 1], label for the node 2\n",
        "* subgraph with nodes [0, 1, 2], label for the node 3\n",
        "* subgraph with nodes [0, 1, 2, 3], label for the node 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "oPuRv8L-JRJW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a0fb7eca0623c7cf61d9dc417fa6a8e",
          "grade": false,
          "grade_id": "cell-b3e7bca9ea472790",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "class GridDataset(DGLDataset):\n",
        "    def __init__(self, feat_dim, min_dim, max_dim, n_graphs):\n",
        "        self.feat_dim = feat_dim\n",
        "        self.min_dim = min_dim\n",
        "        self.max_dim = max_dim\n",
        "        self.n_graphs = n_graphs\n",
        "        self.graphs = None\n",
        "        self.labels = None\n",
        "        super().__init__(name='grid')\n",
        "\n",
        "    def process(self):\n",
        "        graphs = []\n",
        "        labels = []\n",
        "        for graph in grid_graphs(self.min_dim, self.max_dim, self.n_graphs, self.feat_dim):\n",
        "            adj = graph.adj().to_dense()\n",
        "            for i in range(1, graph.number_of_nodes()):\n",
        "                graphs.append(graph.subgraph(range(i)))\n",
        "                subgraph_labels = torch.tensor([k for k in adj[:i + 1, :i][-1]]).reshape(-1, 1)\n",
        "                labels.append(subgraph_labels)\n",
        "        self.graphs = graphs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx], self.labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xwOcZmgNOyIi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a7dadf7d8dd7e3e1b441b07a1a06fd1d",
          "grade": true,
          "grade_id": "cell-4d8cfd7ec97e1ec3",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "feat_dim = 40\n",
        "min_dim = 3\n",
        "max_dim = 6\n",
        "n_graphs = 100\n",
        "grid_dataset = GridDataset(feat_dim, min_dim, max_dim, n_graphs)\n",
        "assert n_graphs < len(grid_dataset) < n_graphs * max_dim**2\n",
        "n_nodes = torch.tensor([g.number_of_nodes() for g, l in grid_dataset])\n",
        "assert n_nodes.min() == 1\n",
        "assert n_nodes.max() == max_dim**2 - 1\n",
        "g, l = grid_dataset[1]\n",
        "assert l.shape == (2, 1)\n",
        "g, l = grid_dataset[2]\n",
        "assert l.shape == (3, 1)\n",
        "assert np.all([g.number_of_nodes() == l.shape[0] for g, l in grid_dataset])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3RbUadc2Uvl",
        "outputId": "10bfb344-37a3-4f34-96cd-c5644ea78246"
      },
      "source": [
        "len(grid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1977"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A9SUjIJX1kM"
      },
      "source": [
        "Finally, create a train dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpWefrbPX8Pw",
        "outputId": "86589efa-708c-4313-c62a-21e98f1db60f"
      },
      "source": [
        "def collate(sample):\n",
        "    graphs, labels = map(list, zip(*sample))\n",
        "    graph = dgl.batch(graphs)\n",
        "    labels = torch.cat(labels)\n",
        "    return graph, labels\n",
        "\n",
        "grid_dataset = GridDataset(feat_dim=40, min_dim=4, max_dim=6, n_graphs=20)\n",
        "dataloader = DataLoader(\n",
        "    grid_dataset, batch_size=128, collate_fn=collate, shuffle=True)\n",
        "\n",
        "for g, l in dataloader:\n",
        "    break\n",
        "len(dataloader), g.batch_num_nodes(), g.number_of_nodes(), l.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5,\n",
              " tensor([ 8, 22, 11, 16, 11, 29, 13, 32, 12,  7, 21, 26,  4, 21, 12, 24, 27,  3,\n",
              "         33, 17,  1, 10,  5,  8,  1, 24, 22, 13, 17, 16, 15, 26, 15,  3,  8, 17,\n",
              "         27, 34, 17,  8,  9,  2,  3, 24,  2, 22, 15, 22,  3,  3,  6, 24,  8, 23,\n",
              "         19, 20,  8, 19,  5,  1, 23, 17, 16,  3, 20, 16,  5, 17, 25, 16, 13,  7,\n",
              "          3, 13,  4,  7,  9,  4, 20,  1, 14, 29, 11,  5, 27, 31, 21,  1,  1,  6,\n",
              "          4, 18, 25, 17, 17, 24, 20,  9,  5, 32, 28, 17,  4, 13, 23, 11, 10, 24,\n",
              "          8,  8, 18,  4, 12, 20,  1, 28, 21, 11, 11, 16, 24, 11, 30, 15, 14,  3,\n",
              "         13, 13]),\n",
              " 1841,\n",
              " torch.Size([1841, 1]))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxwPlhzKRDd"
      },
      "source": [
        "### Task 6. Mini-batch training process (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOhFRa8pdbgu"
      },
      "source": [
        "Write a finction `train`. Here is a simple training process: calculate the NLL loss and make an optimization step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "CZMjgePUXr7y",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff33820231b18f0ca7fbf3a2b0776149",
          "grade": false,
          "grade_id": "cell-aede22655bc62312",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def train(model, dataloader, opt):\n",
        "    loss_values = []\n",
        "    for graph, label in dataloader:\n",
        "        opt.zero_grad()\n",
        "        logits = model(graph, graph.ndata['feat'])\n",
        "        loss = bernoulli_nll(logits, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_values.append(loss)\n",
        "    return sum(loss_values) / len(loss_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi9i-m3Ob3Yz"
      },
      "source": [
        "model = BernoulliGNN(in_dim=40, hid_dim=128, num_layer=5)\n",
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDBOslTKEm8y"
      },
      "source": [
        "The training process takes about 10 minutes in Colab on CPU and about a minute in Colab on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6383670d95f34a5d8e5a7b8bab521e85",
            "8517834449e9476f93e6ddf4a52ed3eb",
            "bbd28f6a17924d24b17a44f9f422d62e",
            "e2f121fc79e14c0597c2d950b658282e",
            "5fd1d9dd7bf74aa09cacb109b1516aea",
            "bbe27cf1be464fa8b5bce83d08c77bdd",
            "03213a37b3f6490cb411b9bd4b3f6777",
            "0787bd454fa443edbca3267a0c44c54c",
            "4bcc4f031dc544ef902fb5fb521cd9c3",
            "83d389ec3e6f4b45b106b926818b565a",
            "a694afaddb51498ba74b1dc4d5f48698",
            "767533fe65ef444fa46d253218dca9ed"
          ]
        },
        "id": "3mx7Sbuzbze7",
        "outputId": "1fd76de5-85f0-401e-976f-fbb89c88b54c"
      },
      "source": [
        "opt = Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "n_epochs = 500\n",
        "for e in trange(n_epochs):\n",
        "    loss = train(model, dataloader, opt)\n",
        "    if e % 50 == 0 or e+1 == n_epochs:\n",
        "        print(f'Epoch: {e+1}/{n_epochs}, NLL loss: {loss:.4f}')\n",
        "        #plt.figure(figsize=(2,2))\n",
        "        graph, feat = generate_graph(model, n_nodes=16, feat_dim=40)\n",
        "        G = nx.Graph(graph.cpu().to_networkx())\n",
        "        G.remove_edges_from(nx.selfloop_edges(G))\n",
        "        #nx.draw_kamada_kawai(G, node_size=30)\n",
        "        #plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "767533fe65ef444fa46d253218dca9ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/500, NLL loss: 0.6723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjCmLbdUfm8y"
      },
      "source": [
        "Let us generate a few graphs from the model. They should be visually close to grid graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr0YNFrfd6MG"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for j in range(9):\n",
        "    plt.subplot(3, 3, j+1)\n",
        "    graph, feat = generate_graph(model, n_nodes=18, feat_dim=40)\n",
        "    G = nx.Graph(graph.cpu().to_networkx())\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "    nx.draw_kamada_kawai(G, node_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9XM2KeVFP2y"
      },
      "source": [
        "The next cell checks that at least one graph in a sample is close to a grid. It is possible with approximately 0.05 NLL loss. Note that all hyperparameters can be modified to achive the desired result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Z62onlA8-Zlz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8ae0bd79f30ef64f82cb46f2f01757e",
          "grade": true,
          "grade_id": "cell-813411b980a8355d",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "close_to_grid = False\n",
        "for i in range(20):\n",
        "    graph, feat = generate_graph(model, n_nodes=18, feat_dim=40)\n",
        "    G = nx.Graph(graph.cpu().to_networkx())\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "    hist = nx.degree_histogram(G)\n",
        "    correct_degrees = sum(hist[2:5])\n",
        "    incorrec_degrees = sum(hist) - correct_degrees\n",
        "    close_to_grid = nx.is_connected(G) and correct_degrees > 0 and incorrec_degrees == 0\n",
        "    if close_to_grid: break\n",
        "assert close_to_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb7STTQcKTkn"
      },
      "source": [
        "### Task 7. Kolmogorov Smirnov distance score (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xclX7ql4IFkm"
      },
      "source": [
        "Let us check the model on real graphs. Let a quality metric be the closeness of generated graphs to real graphs. We will compute the sum of KS distances between distributions of statistics: clustering coefficients, laplacian spectrum values, node degrees.\n",
        "\n",
        "Write a function `ks_score` that takes a list of real graphs, a list of generated (fake) graphs and computes the sum of KS distances. The input graphs are DGL graphs.\n",
        "\n",
        "*Hint: use `ks_2samp`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "eU4q388qJIWy",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0608bea7f905363a81aef70210ed3d14",
          "grade": false,
          "grade_id": "cell-d8723c0c56e00f6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def ks_score(fake_graphs, real_graphs):\n",
        "    real_graphs = [nx.Graph(g.to_networkx()) for g in real_graphs]\n",
        "    fake_graphs = [nx.Graph(g.to_networkx()) for g in fake_graphs]\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f9Ykr3VeMMAh",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1891cc974ea64bbd451a9fa54e10849e",
          "grade": true,
          "grade_id": "cell-7b55deea59c3e597",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "rand_graph = dgl.from_networkx(nx.erdos_renyi_graph(10, 30))\n",
        "grid55_graph = dgl.from_networkx(nx.grid_2d_graph(5, 5))\n",
        "grid44_graph = dgl.from_networkx(nx.grid_2d_graph(4, 4))\n",
        "score = ks_score([rand_graph], [grid55_graph])\n",
        "assert score == 2.9\n",
        "score = ks_score([grid55_graph], [grid55_graph])\n",
        "assert score == 0\n",
        "score = ks_score([grid55_graph], [grid44_graph])\n",
        "assert score == 0.29"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEh-lDbvKal0"
      },
      "source": [
        "### Task 8. DFS from top degree node ordering (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFKB33uORf8H"
      },
      "source": [
        "So far, we have tested our model on grid graphs that have predefined node ordering. It helps us to train the model, but real networks are arbitrary ordered and so we need to select certain node ordering to train the model. There are many approaches: node degree, DFS/BFS from top node degree, k-core decomposition and so on. In this assignment, let us select DFS from top degree node.\n",
        "\n",
        "Write a function `dfs_ordering` that takes a DGL graph and returns a tensor (array) of nodes where the first node is the top degree node and others are ordered by DFS from the top degree node. We assume that the graph has a single connected component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "TNN1F4QrQ8yz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3c75ec5edab02e2e45a93842c292f4e8",
          "grade": false,
          "grade_id": "cell-c24c188e39a9e24e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def dfs_ordering(graph):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4-8IgqMrY1XW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "69aa256f00298cae5c942bfec091eb96",
          "grade": true,
          "grade_id": "cell-7bdc780eae68d288",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "G = nx.complete_graph(5)\n",
        "G.add_edges_from([[0, -1], [-1, -2], [-2, -3]])\n",
        "graph = dgl.from_networkx(G)\n",
        "ord = dfs_ordering(graph)\n",
        "assert ord.shape == (8, )\n",
        "adj = graph.adj().to_dense()\n",
        "assert torch.all(adj[ord, :][:, ord][0] == torch.tensor([0, 1, 1, 1, 1, 1, 0, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9CplsJh1WHZ"
      },
      "source": [
        "### Task 9. Erdos-Renyi model baseline (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lEPnxH8amSq"
      },
      "source": [
        "Create a simple baseline — Erdos-Renyi model.\n",
        "\n",
        "Write a function `fit` that takes a list of DGL graphs and estimates the parameter $p$ of Erdos-Renyi model.\n",
        "\n",
        "Write a function `sample` that generates an Erdos-Renyi graph with parameter $n$ and $p$. The output graph is DGL graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "88mItcukat-h",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "14edba2e1548bd747278a6516e8484fe",
          "grade": false,
          "grade_id": "cell-e3efcb51cf9a0df1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "class ErdosRenyi():\n",
        "    def __init__(self):\n",
        "        self.p = None\n",
        "    def fit(self, graphs):\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "    def sample(self, n):\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DNPCTT-WdSo6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c186f05ac1bdbfda3cc4ed6f27f6ae05",
          "grade": true,
          "grade_id": "cell-f5b166faa5bb98cc",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "graphs = [dgl.rand_graph(10, 50), dgl.rand_graph(20, 100)]\n",
        "er_model = ErdosRenyi()\n",
        "er_model.fit(graphs)\n",
        "assert er_model.p == (0.5 + 0.25) / 2\n",
        "er_graph = er_model.sample(10)\n",
        "assert 24 < er_graph.number_of_edges() < 51"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOcKFjbhZ0Z3"
      },
      "source": [
        "### Task 10. Results on protein dataset (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twLTGjQInM3"
      },
      "source": [
        "proteins_dataset = GINDataset('PROTEINS', self_loop=True)\n",
        "len(proteins_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVL1rDaxRf9G"
      },
      "source": [
        "Let us test our model on proteins dataset. We will only learn small graphs for simplicity. Also we drops graph with multiple connected components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzzJthVoRrRq"
      },
      "source": [
        "proteins_dataset = GINDataset('PROTEINS', self_loop=True)\n",
        "small_graphs_idx = []\n",
        "for i in range(len(proteins_dataset)):\n",
        "    graph = proteins_dataset.graphs[i]\n",
        "    if graph.number_of_nodes() <= 40:\n",
        "        n_nodes = len(torch.cat(dgl.bfs_nodes_generator(graph, 0)))\n",
        "        if graph.number_of_nodes() == n_nodes:\n",
        "            small_graphs_idx.append(i)\n",
        "proteins_dataset = Subset(proteins_dataset, small_graphs_idx)\n",
        "len(proteins_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMzw6REzWOOU"
      },
      "source": [
        "Let us split the dataset into a train and test sets. We will use the train set to train the model and use the test set to calculate KS distance score between real and fake graphs. Let the train ratio be approximately 0.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRCXsHQrWN6P"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "train_mask = torch.rand(len(proteins_dataset)) < 0.3\n",
        "train_idx = torch.where(train_mask)[0]\n",
        "train_proteins_set = Subset(proteins_dataset, train_idx)\n",
        "test_idx = torch.where(~train_mask)[0]\n",
        "test_proteins_set = Subset(proteins_dataset, test_idx)\n",
        "len(train_proteins_set), len(test_proteins_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZp9wApVZSZ9"
      },
      "source": [
        "Check that train and test are close with respect to KS distanse score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KlTNG8cYvFa"
      },
      "source": [
        "_train = [g for g, l in train_proteins_set]\n",
        "_test = [g for g, l in test_proteins_set]\n",
        "print(f'KS score: {ks_score(_train, _test):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwEYr5NDUo3r"
      },
      "source": [
        "Also we want to learn distribution of number of nodes to generate graphs with different number of nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgkG7eHtU-Js"
      },
      "source": [
        "n_nodes_seq = [g.number_of_nodes() for g, l in proteins_dataset]\n",
        "plt.hist(n_nodes_seq);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JfKP2KRegHP"
      },
      "source": [
        "Generate graphs from Erdos Renyi model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXIVxLkDeEsG"
      },
      "source": [
        "fake_graphs = [er_model.sample(np.random.choice(n_nodes_seq)) for _ in range(100)]\n",
        "print(f'KS score: {ks_score(fake_graphs, _test):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dTD-uVPfINL"
      },
      "source": [
        "Next, prepare the dataset for the GNN model (similar to the grid dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "mC_X5eI4ZgbS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2564a0924815d158fbdc35416b822b65",
          "grade": false,
          "grade_id": "cell-51eceb95af25cc05",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "class GraphDataset(DGLDataset):\n",
        "    def __init__(self, initial_set, feat_dim):\n",
        "        self.initial_set = initial_set\n",
        "        self.feat_dim = feat_dim\n",
        "        self.graphs = None\n",
        "        self.labels = None\n",
        "        super().__init__(name='grid')\n",
        "\n",
        "    def process(self):\n",
        "        graphs = []\n",
        "        labels = []\n",
        "        for graph in self.initial_set:\n",
        "            ord = dfs_ordering(graph)\n",
        "            graph = dgl.reorder_graph(\n",
        "                graph, 'custom', permute_config={'nodes_perm':ord})\n",
        "            feat = torch.eye(graph.number_of_nodes())\n",
        "            feat = F.pad(feat, [0, self.feat_dim - graph.number_of_nodes(), 0, 0])\n",
        "            graph.ndata['feat'] = feat\n",
        "            # YOUR CODE HERE\n",
        "            raise NotImplementedError()\n",
        "        self.graphs = graphs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx], self.labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XHkJ67AugVN_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f0eea3ab6be0cd0af01319c5b6aed3a2",
          "grade": true,
          "grade_id": "cell-ffcc8a2e777c3b83",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "graph_dataset = GraphDataset(_train, feat_dim=40)\n",
        "assert len(graph_dataset) == 4701"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7WRfPqig9go"
      },
      "source": [
        "dataloader = DataLoader(\n",
        "    graph_dataset, batch_size=512, collate_fn=collate, shuffle=True)\n",
        "len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UJcfWAHg32Z"
      },
      "source": [
        "Train the model. To pass time limits, load the model parameters using loading Torch interface: https://pytorch.org/tutorials/beginner/saving_loading_models.html. There is also a way to speed the training process using iterations over blocks of nodes (details are in [Liao et al., 2019](https://arxiv.org/pdf/1910.00760.pdf)). In this assignment, the block size is 1 for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "dZ0CA7Zh8SFg",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "869196f729bbb8bcc37eec98bfe7bc5c",
          "grade": false,
          "grade_id": "cell-caed9239ef4d6c41",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def train_on_proteins(dataloader):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    # model = your model\n",
        "    # url = link to parameters\n",
        "    # open('params', 'wb').write(requests.get(url).content)\n",
        "    # model.load_state_dict(torch.load('params'))\n",
        "    # return model\n",
        "\n",
        "    model = BernoulliGNN(in_dim=40, hid_dim=128, num_layer=5)\n",
        "    model.to(device);\n",
        "    opt = Adam(model.parameters(), lr=0.0005)\n",
        "    n_epochs = 1000\n",
        "    for e in trange(n_epochs):\n",
        "        loss = train(model, dataloader, opt)\n",
        "        if e % 50 == 0 or e+1 == n_epochs:\n",
        "            print(f'Epoch: {e+1}/{n_epochs}, NLL loss: {loss:.4f}')\n",
        "            plt.figure(figsize=(2,2))\n",
        "            graph, feat = generate_graph(model, n_nodes=30, feat_dim=40)\n",
        "            G = nx.Graph(graph.cpu().to_networkx())\n",
        "            G.remove_edges_from(nx.selfloop_edges(G))\n",
        "            nx.draw_kamada_kawai(G, node_size=30)\n",
        "            plt.show()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "h45NOeIyAJCc",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8b61d688ca4fb90673b181c7f10bdda",
          "grade": true,
          "grade_id": "cell-ac5f2ef782a08e49",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "model = train_on_proteins(dataloader)\n",
        "fake_graphs = []\n",
        "for _ in range(100):\n",
        "    graph = er_model.sample(np.random.choice(n_nodes_seq))\n",
        "    fake_graphs.append(graph)\n",
        "er_score = ks_score(fake_graphs, _test)\n",
        "\n",
        "fake_graphs = []\n",
        "for _ in trange(100):\n",
        "    graph, feat = generate_graph(model, np.random.choice(n_nodes_seq), feat_dim)\n",
        "    fake_graphs.append(graph.cpu())\n",
        "gnn_score = ks_score(fake_graphs, _test)\n",
        "\n",
        "assert gnn_score < er_score\n",
        "assert gnn_score < 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlL7D-YqA2ol"
      },
      "source": [
        "print(f'Erdos Renyi KS score: {er_score:.4f}')\n",
        "print(f'GNN model KS score: {gnn_score:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-XgXCy5vRkN"
      },
      "source": [
        "Examples of real graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HatCJvVvQ1L"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for j in range(9):\n",
        "    plt.subplot(3, 3, j+1)\n",
        "    graph = np.random.choice(_test)\n",
        "    G = nx.Graph(graph.cpu().to_networkx())\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "    nx.draw_kamada_kawai(G, node_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6tF7yD2vVHn"
      },
      "source": [
        "Examples of fake graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92NGVUiau0Zj"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for j in range(9):\n",
        "    plt.subplot(3, 3, j+1)\n",
        "    graph, feat = generate_graph(model, n_nodes=np.random.choice(n_nodes_seq), feat_dim=40)\n",
        "    G = nx.Graph(graph.cpu().to_networkx())\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "    nx.draw_kamada_kawai(G, node_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJLgkvhJxcvc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}