{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"asr_lab_4_new.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RcyxmRJGqlY"
      },
      "source": [
        "# Практика №4\n",
        "\n",
        "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbO_rrWGq7j"
      },
      "source": [
        "### Bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzJyomV1JaLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea1ba77-8a2a-4ac0-e87e-003c30dce25c"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TROAsHTXHWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e38415f-46a7-4db5-8b49-4b11846d3c81"
      },
      "source": [
        "!gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
        "\n",
        "!unzip -q lab4.zip\n",
        "!rm -rf lab4.zip sample_data\n",
        "%cd lab4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
            "To: /content/lab4.zip\n",
            "\r0.00B [00:00, ?B/s]\r2.77MB [00:00, 24.5MB/s]\n",
            "/content/lab4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4wcCtkIH2dn"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from utils import TextTransform\n",
        "from utils import cer\n",
        "from utils import wer\n",
        "\n",
        "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
        "from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer\n",
        "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
        "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
        "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
        "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
        "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaESUZiHJgfN"
      },
      "source": [
        "train_audio_transforms = torch.nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
        "                                                              n_fft=400,\n",
        "                                                              hop_length=160,\n",
        "                                                              n_mels=80)\n",
        "\n",
        "#text_transform = TextTransform()\n",
        "\n",
        "#-----------------------------TODO №2-----------------------------------\n",
        "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
        "#-----------------------------------------------------------------------\n",
        "text_transform = TextTransformBPE('/content/lab4/train_clean_100_text_clean.txt')\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0])\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=4000, collapse_repeated=True):\n",
        "    arg_maxes = torch.argmax(output, dim=2)\n",
        "    decodes = []\n",
        "    targets = []\n",
        "    for i, args in enumerate(arg_maxes):\n",
        "        decode = []\n",
        "        targets.append(text_transform.int_to_text([int(u) for u in labels[i][:label_lengths[i]].tolist()]))\n",
        "        for j, index in enumerate(args):\n",
        "            if index != blank_label:\n",
        "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
        "                    continue\n",
        "                decode.append(index.item())\n",
        "        decodes.append(text_transform.int_to_text(decode))\n",
        "    return decodes, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OqoVLnrJsCV"
      },
      "source": [
        "class TransformerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=80,\n",
        "        output_size=4001,\n",
        "        conv2d_filters=32,\n",
        "        attention_dim=360,\n",
        "        attention_heads=8,\n",
        "        feedforward_dim=1024,\n",
        "        num_layers=10,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        \n",
        "        self.conv_in = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.conv_out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(conv2d_filters * ((input_size // 2) // 2), attention_dim),\n",
        "            PositionalEncoding(attention_dim, 0.1),\n",
        "        )\n",
        "        positionwise_layer = PositionwiseFeedForward\n",
        "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
        "        self.encoder_layer = repeat(\n",
        "            num_layers,\n",
        "            lambda lnum: EncoderLayer(\n",
        "                attention_dim,\n",
        "                MultiHeadedAttention(\n",
        "                    attention_heads, attention_dim, dropout\n",
        "                ),\n",
        "                positionwise_layer(*positionwise_layer_args),\n",
        "                dropout,\n",
        "                normalize_before=True,\n",
        "                concat_after=False,\n",
        "            ),\n",
        "        )\n",
        "        self.after_norm = LayerNorm(attention_dim)\n",
        "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
        "\n",
        "    def forward(self, x, ilens):\n",
        "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
        "        x = self.conv_in(x)\n",
        "        b, c, t, f = x.size()\n",
        "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
        "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
        "        x, _ = self.encoder_layer(x, masks)\n",
        "        x = self.after_norm(x)\n",
        "        x = self.final_layer(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p_8IjeKkqq"
      },
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
        "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "        input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item(), scheduler.get_last_lr()[0]))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
        "            \n",
        "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "            input_lengths = [x // 4 for x in input_lengths]\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEbtsB1LKsh"
      },
      "source": [
        "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    \n",
        "    hparams = {\n",
        "        \"input_size\": 80,\n",
        "        \"output_size\": 4001,\n",
        "        \"conv2d_filters\": 32,\n",
        "        \"attention_dim\": 360,\n",
        "        \"attention_heads\": 8,\n",
        "        \"feedforward_dim\": 1024,\n",
        "        \"num_layers\":10,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=test_batch_size,\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        hparams['input_size'],\n",
        "        hparams['output_size'],\n",
        "        hparams['conv2d_filters'],\n",
        "        hparams['attention_dim'],\n",
        "        hparams['attention_heads'],\n",
        "        hparams['feedforward_dim'],\n",
        "        hparams['num_layers'],\n",
        "        hparams['dropout']).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        !date\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        test(model, device, test_loader, criterion, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExZLsUiLeXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bbd722-1461-403b-d5f6-879f2d564824"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 10\n",
        "test_batch_size = 7\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TransformerModel(\n",
            "  (conv_in): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=360, bias=True)\n",
            "    (1): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (encoder_layer): MultiSequential(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (3): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (4): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (5): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (6): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (7): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (8): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "    (9): EncoderLayer(\n",
            "      (self_attn): MultiHeadedAttention(\n",
            "        (linear_q): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_k): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_v): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (linear_out): Linear(in_features=360, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (feed_forward): PositionwiseFeedForward(\n",
            "        (w_1): Linear(in_features=360, out_features=1024, bias=True)\n",
            "        (w_2): Linear(in_features=1024, out_features=360, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (norm1): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (concat_linear): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (after_norm): LayerNorm((360,), eps=1e-12, elementwise_affine=True)\n",
            "  (final_layer): Linear(in_features=360, out_features=4001, bias=True)\n",
            ")\n",
            "Num Model Parameters 14284849\n",
            "Sun May  2 20:14:20 UTC 2021\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 36.746391\tLR: 0.000040\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 0.422583\tLR: 0.000051\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 0.178303\tLR: 0.000063\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 0.172888\tLR: 0.000074\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 0.124800\tLR: 0.000085\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 0.079592\tLR: 0.000096\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 0.127676\tLR: 0.000107\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 0.162326\tLR: 0.000119\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 0.079077\tLR: 0.000130\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 0.060531\tLR: 0.000141\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 0.103647\tLR: 0.000152\n",
            "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 0.102569\tLR: 0.000163\n",
            "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 0.092953\tLR: 0.000175\n",
            "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 0.111824\tLR: 0.000186\n",
            "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 0.115189\tLR: 0.000197\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 0.147671\tLR: 0.000208\n",
            "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 0.109062\tLR: 0.000220\n",
            "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 0.122660\tLR: 0.000231\n",
            "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 0.077584\tLR: 0.000242\n",
            "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 0.078901\tLR: 0.000253\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 0.139995\tLR: 0.000264\n",
            "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 0.100704\tLR: 0.000276\n",
            "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 0.084047\tLR: 0.000287\n",
            "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 0.063577\tLR: 0.000298\n",
            "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 0.057293\tLR: 0.000309\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 0.101073\tLR: 0.000320\n",
            "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 0.072572\tLR: 0.000332\n",
            "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 0.094733\tLR: 0.000343\n",
            "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 0.088203\tLR: 0.000354\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1845, Average CER: 0.374156 Average WER: 0.3508\n",
            "\n",
            "Sun May  2 20:28:54 UTC 2021\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 0.080167\tLR: 0.000360\n",
            "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 0.071952\tLR: 0.000371\n",
            "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 0.125880\tLR: 0.000383\n",
            "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 0.099167\tLR: 0.000394\n",
            "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 0.070201\tLR: 0.000405\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 0.116308\tLR: 0.000416\n",
            "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 0.067564\tLR: 0.000427\n",
            "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 0.099250\tLR: 0.000439\n",
            "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 0.138328\tLR: 0.000450\n",
            "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 0.135373\tLR: 0.000461\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 0.087370\tLR: 0.000472\n",
            "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 0.084768\tLR: 0.000483\n",
            "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 0.082659\tLR: 0.000495\n",
            "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 0.096627\tLR: 0.000506\n",
            "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 0.075657\tLR: 0.000517\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 0.160296\tLR: 0.000528\n",
            "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 0.165071\tLR: 0.000540\n",
            "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 0.134712\tLR: 0.000551\n",
            "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 0.306733\tLR: 0.000562\n",
            "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 0.084051\tLR: 0.000573\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 0.132560\tLR: 0.000584\n",
            "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 0.074136\tLR: 0.000596\n",
            "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 0.118411\tLR: 0.000607\n",
            "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 0.064697\tLR: 0.000618\n",
            "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 0.069489\tLR: 0.000629\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 0.072644\tLR: 0.000640\n",
            "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 0.153584\tLR: 0.000652\n",
            "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 0.063179\tLR: 0.000663\n",
            "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 0.069914\tLR: 0.000674\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1784, Average CER: 0.607179 Average WER: 0.5781\n",
            "\n",
            "Sun May  2 20:43:03 UTC 2021\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 0.057608\tLR: 0.000680\n",
            "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 0.140885\tLR: 0.000691\n",
            "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 0.088478\tLR: 0.000703\n",
            "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 0.103409\tLR: 0.000714\n",
            "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 0.175443\tLR: 0.000725\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 0.093620\tLR: 0.000736\n",
            "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 0.089518\tLR: 0.000747\n",
            "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 0.054829\tLR: 0.000759\n",
            "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 0.089106\tLR: 0.000770\n",
            "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 0.061631\tLR: 0.000781\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 0.088343\tLR: 0.000792\n",
            "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 0.056144\tLR: 0.000804\n",
            "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 0.138052\tLR: 0.000815\n",
            "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 0.050985\tLR: 0.000826\n",
            "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 0.076439\tLR: 0.000837\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 0.155831\tLR: 0.000848\n",
            "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 0.135877\tLR: 0.000860\n",
            "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 0.049031\tLR: 0.000871\n",
            "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 0.115715\tLR: 0.000882\n",
            "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 0.175626\tLR: 0.000893\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 0.103279\tLR: 0.000904\n",
            "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 0.095876\tLR: 0.000916\n",
            "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 0.076450\tLR: 0.000927\n",
            "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 0.063606\tLR: 0.000938\n",
            "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 0.087367\tLR: 0.000949\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 0.122448\tLR: 0.000961\n",
            "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 0.099162\tLR: 0.000972\n",
            "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 0.093967\tLR: 0.000983\n",
            "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 0.192296\tLR: 0.000994\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1966, Average CER: 0.359307 Average WER: 0.3356\n",
            "\n",
            "Sun May  2 20:57:33 UTC 2021\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 0.124653\tLR: 0.001000\n",
            "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 0.110198\tLR: 0.000995\n",
            "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 0.105021\tLR: 0.000990\n",
            "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 0.092536\tLR: 0.000985\n",
            "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 0.085833\tLR: 0.000980\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 0.087738\tLR: 0.000975\n",
            "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 0.164088\tLR: 0.000970\n",
            "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 0.088462\tLR: 0.000965\n",
            "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 0.072823\tLR: 0.000960\n",
            "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 0.080980\tLR: 0.000955\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 0.093961\tLR: 0.000950\n",
            "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 0.105865\tLR: 0.000945\n",
            "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 0.068067\tLR: 0.000940\n",
            "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 0.078147\tLR: 0.000935\n",
            "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 0.067506\tLR: 0.000930\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 0.118711\tLR: 0.000925\n",
            "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 0.068070\tLR: 0.000920\n",
            "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 0.065484\tLR: 0.000915\n",
            "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 0.094239\tLR: 0.000910\n",
            "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 0.184031\tLR: 0.000905\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 0.091583\tLR: 0.000900\n",
            "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 0.140157\tLR: 0.000895\n",
            "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 0.096665\tLR: 0.000890\n",
            "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 0.089634\tLR: 0.000885\n",
            "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 0.061107\tLR: 0.000880\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 0.154722\tLR: 0.000875\n",
            "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 0.224649\tLR: 0.000870\n",
            "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 0.101805\tLR: 0.000865\n",
            "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 0.128191\tLR: 0.000860\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1834, Average CER: 0.536391 Average WER: 0.5096\n",
            "\n",
            "Sun May  2 21:11:43 UTC 2021\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 0.052237\tLR: 0.000857\n",
            "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 0.082141\tLR: 0.000852\n",
            "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 0.070435\tLR: 0.000847\n",
            "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 0.140025\tLR: 0.000842\n",
            "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 0.101196\tLR: 0.000837\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 0.061813\tLR: 0.000832\n",
            "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 0.093514\tLR: 0.000827\n",
            "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 0.077757\tLR: 0.000822\n",
            "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 0.148725\tLR: 0.000817\n",
            "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 0.182130\tLR: 0.000812\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 0.147592\tLR: 0.000807\n",
            "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 0.138273\tLR: 0.000802\n",
            "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 0.081559\tLR: 0.000797\n",
            "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 0.096645\tLR: 0.000792\n",
            "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 0.072343\tLR: 0.000787\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 0.119039\tLR: 0.000782\n",
            "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 0.096245\tLR: 0.000777\n",
            "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 0.069042\tLR: 0.000772\n",
            "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 0.155587\tLR: 0.000767\n",
            "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 0.094738\tLR: 0.000762\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 0.055791\tLR: 0.000757\n",
            "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 0.093776\tLR: 0.000752\n",
            "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 0.089390\tLR: 0.000747\n",
            "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 0.101447\tLR: 0.000742\n",
            "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 0.068303\tLR: 0.000737\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 0.088600\tLR: 0.000732\n",
            "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 0.082928\tLR: 0.000727\n",
            "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 0.070657\tLR: 0.000722\n",
            "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 0.189716\tLR: 0.000717\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1835, Average CER: 0.627745 Average WER: 0.5988\n",
            "\n",
            "Sun May  2 21:25:43 UTC 2021\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 0.074263\tLR: 0.000714\n",
            "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 0.100666\tLR: 0.000709\n",
            "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 0.127384\tLR: 0.000704\n",
            "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 0.071357\tLR: 0.000699\n",
            "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 0.116958\tLR: 0.000694\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 0.080972\tLR: 0.000689\n",
            "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 0.060057\tLR: 0.000684\n",
            "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 0.088232\tLR: 0.000679\n",
            "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 0.095830\tLR: 0.000674\n",
            "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 0.096786\tLR: 0.000669\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 0.090371\tLR: 0.000664\n",
            "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 0.121967\tLR: 0.000659\n",
            "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 0.105990\tLR: 0.000654\n",
            "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 0.112638\tLR: 0.000649\n",
            "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 0.101531\tLR: 0.000644\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 0.098578\tLR: 0.000639\n",
            "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 0.107089\tLR: 0.000634\n",
            "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 0.335117\tLR: 0.000629\n",
            "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 0.069176\tLR: 0.000624\n",
            "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 0.089435\tLR: 0.000619\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 0.070164\tLR: 0.000614\n",
            "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 0.086682\tLR: 0.000609\n",
            "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 0.074301\tLR: 0.000604\n",
            "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 0.148426\tLR: 0.000599\n",
            "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 0.115485\tLR: 0.000594\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 0.081485\tLR: 0.000589\n",
            "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 0.092697\tLR: 0.000584\n",
            "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 0.115778\tLR: 0.000579\n",
            "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 0.061562\tLR: 0.000574\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1845, Average CER: 0.604240 Average WER: 0.5759\n",
            "\n",
            "Sun May  2 21:39:45 UTC 2021\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 0.057228\tLR: 0.000571\n",
            "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.069575\tLR: 0.000566\n",
            "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 0.082747\tLR: 0.000561\n",
            "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 0.097834\tLR: 0.000556\n",
            "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 0.097570\tLR: 0.000551\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 0.077701\tLR: 0.000546\n",
            "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 0.097594\tLR: 0.000541\n",
            "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 0.085020\tLR: 0.000536\n",
            "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 0.101205\tLR: 0.000531\n",
            "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 0.056722\tLR: 0.000526\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 0.075415\tLR: 0.000521\n",
            "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 0.108263\tLR: 0.000516\n",
            "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 0.066311\tLR: 0.000511\n",
            "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 0.104632\tLR: 0.000506\n",
            "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 0.098717\tLR: 0.000501\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.086938\tLR: 0.000496\n",
            "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 0.069054\tLR: 0.000491\n",
            "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 0.111624\tLR: 0.000486\n",
            "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.055711\tLR: 0.000481\n",
            "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 0.102445\tLR: 0.000476\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 0.087402\tLR: 0.000471\n",
            "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 0.081525\tLR: 0.000466\n",
            "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 0.102985\tLR: 0.000461\n",
            "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 0.121595\tLR: 0.000456\n",
            "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 0.041991\tLR: 0.000451\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.087751\tLR: 0.000446\n",
            "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 0.090467\tLR: 0.000441\n",
            "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 0.078315\tLR: 0.000436\n",
            "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 0.111023\tLR: 0.000431\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1769, Average CER: 0.645576 Average WER: 0.6163\n",
            "\n",
            "Sun May  2 21:53:41 UTC 2021\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.069988\tLR: 0.000428\n",
            "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 0.062596\tLR: 0.000423\n",
            "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 0.071614\tLR: 0.000418\n",
            "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 0.104015\tLR: 0.000413\n",
            "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.059927\tLR: 0.000408\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.090369\tLR: 0.000403\n",
            "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 0.093579\tLR: 0.000398\n",
            "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 0.103222\tLR: 0.000393\n",
            "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 0.062712\tLR: 0.000388\n",
            "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.092963\tLR: 0.000383\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 0.104243\tLR: 0.000378\n",
            "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.074535\tLR: 0.000373\n",
            "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.075546\tLR: 0.000368\n",
            "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.064578\tLR: 0.000363\n",
            "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.065906\tLR: 0.000358\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.150930\tLR: 0.000353\n",
            "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.099340\tLR: 0.000348\n",
            "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 0.077498\tLR: 0.000343\n",
            "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 0.073748\tLR: 0.000338\n",
            "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 0.066581\tLR: 0.000333\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 0.093008\tLR: 0.000328\n",
            "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 0.087858\tLR: 0.000323\n",
            "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.081884\tLR: 0.000318\n",
            "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.092969\tLR: 0.000313\n",
            "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 0.070671\tLR: 0.000308\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.094313\tLR: 0.000303\n",
            "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.088784\tLR: 0.000298\n",
            "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.091204\tLR: 0.000293\n",
            "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.249500\tLR: 0.000288\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1842, Average CER: 0.599755 Average WER: 0.5715\n",
            "\n",
            "Sun May  2 22:07:41 UTC 2021\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.079405\tLR: 0.000286\n",
            "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 0.078003\tLR: 0.000281\n",
            "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 0.067516\tLR: 0.000276\n",
            "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.073871\tLR: 0.000271\n",
            "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.099581\tLR: 0.000266\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.073454\tLR: 0.000261\n",
            "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.068145\tLR: 0.000256\n",
            "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.141344\tLR: 0.000251\n",
            "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.068365\tLR: 0.000246\n",
            "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.076340\tLR: 0.000241\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.079942\tLR: 0.000236\n",
            "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.062847\tLR: 0.000231\n",
            "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.060190\tLR: 0.000226\n",
            "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.093073\tLR: 0.000221\n",
            "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.062959\tLR: 0.000216\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.100906\tLR: 0.000211\n",
            "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 0.096018\tLR: 0.000206\n",
            "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 0.089959\tLR: 0.000201\n",
            "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 0.096973\tLR: 0.000196\n",
            "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.075550\tLR: 0.000191\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.058403\tLR: 0.000186\n",
            "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.063545\tLR: 0.000181\n",
            "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.088894\tLR: 0.000175\n",
            "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.112049\tLR: 0.000170\n",
            "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.072406\tLR: 0.000165\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.117321\tLR: 0.000160\n",
            "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 0.084431\tLR: 0.000155\n",
            "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.094341\tLR: 0.000150\n",
            "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 0.089780\tLR: 0.000145\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1763, Average CER: 0.671538 Average WER: 0.6417\n",
            "\n",
            "Sun May  2 22:21:35 UTC 2021\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.133148\tLR: 0.000143\n",
            "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.073327\tLR: 0.000138\n",
            "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.043790\tLR: 0.000133\n",
            "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 0.058628\tLR: 0.000128\n",
            "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.113837\tLR: 0.000123\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.100997\tLR: 0.000118\n",
            "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.062016\tLR: 0.000113\n",
            "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 0.077755\tLR: 0.000108\n",
            "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.104273\tLR: 0.000103\n",
            "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.069196\tLR: 0.000098\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.130719\tLR: 0.000093\n",
            "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.085292\tLR: 0.000088\n",
            "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.077069\tLR: 0.000083\n",
            "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.110704\tLR: 0.000078\n",
            "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.061416\tLR: 0.000073\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.073340\tLR: 0.000068\n",
            "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.119948\tLR: 0.000063\n",
            "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.106868\tLR: 0.000058\n",
            "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.076317\tLR: 0.000053\n",
            "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.093996\tLR: 0.000048\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.091940\tLR: 0.000043\n",
            "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.088268\tLR: 0.000038\n",
            "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.095508\tLR: 0.000033\n",
            "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.065219\tLR: 0.000028\n",
            "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.080343\tLR: 0.000023\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.097962\tLR: 0.000018\n",
            "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.080694\tLR: 0.000013\n",
            "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.054065\tLR: 0.000008\n",
            "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.110813\tLR: 0.000003\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.1765, Average CER: 0.631295 Average WER: 0.6024\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mby39YVqZadd"
      },
      "source": [
        "### <b>Задание №1</b> (5 баллов):\n",
        "На данный момент практически все E2E SOTA решения использую [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Главное правильно обернуть его в наш класс TextTransform. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqo7Obq-qNVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ada293-935a-4e41-a4fe-37b08bb675eb"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 27.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 31.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 24.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 24.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 27.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 20.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 21.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 19.8MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 19.8MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 19.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNbiW919e2le"
      },
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "class TextTransformBPE:\n",
        "    def __init__(self, train_text):\n",
        "        spm.SentencePieceTrainer.train(input=train_text, \n",
        "                                       model_prefix='m', \n",
        "                                       vocab_size=4000)\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.load('m.model')\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
        "        int_sequence = self.sp.encode_as_ids(text)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
        "        string = []\n",
        "        string = self.sp.decode_ids(labels)\n",
        "        return string\n",
        "    \n",
        "    def get_model(self):\n",
        "        return self.sp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV48Q7HqZsAD"
      },
      "source": [
        "### <b>Задание №2</b> (5 баллов):\n",
        "Импровизация по улучшению качества распознавания."
      ]
    }
  ]
}